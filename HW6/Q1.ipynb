{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/implementing-batch-normalization-in-python-a044b0369567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(x, gamma, beta, eps=1e-5):\n",
    "    N, D = x.shape\n",
    "    \n",
    "    sample_mean = x.mean(axis=0)\n",
    "    sample_var = x.var(axis=0)\n",
    "    \n",
    "    std = np.sqrt(sample_var + eps)\n",
    "    x_centered = x - sample_mean\n",
    "    x_norm = x_centered / std\n",
    "    out = gamma * x_norm + beta\n",
    "    \n",
    "    cache = (x_norm, x_centered, std, gamma)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layernorm_forward(x, gamma, beta, eps=1e-5):\n",
    "    N, D = x.shape\n",
    "    \n",
    "    sample_mean = x.mean(axis=1)\n",
    "    sample_var = x.var(axis=1)\n",
    "    \n",
    "    std = np.sqrt(sample_var + eps)\n",
    "    x_centered = x - sample_mean\n",
    "    x_norm = x_centered / std\n",
    "    out = gamma * x_norm + beta\n",
    "    \n",
    "    cache = (x_norm, x_centered, std, gamma)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[20, 17, 32, 42, 65],\n",
    "              [13, 65, 96, 53, 21],\n",
    "              [45, 63, 74, 38, 64],\n",
    "              [23, 76, 40, 34, 26],\n",
    "              [14, 66, 78, 49, 23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Normalization: \n",
      " [[-0.25839035 -1.9522604  -1.32416941 -0.17220346  1.24551176]\n",
      " [-0.86130117  0.36725691  1.32416941  1.40632822 -0.92919132]\n",
      " [ 1.89486258  0.27061035  0.41380294 -0.74621497  1.19608669]\n",
      " [ 0.          0.89881296 -0.99312706 -1.32022649 -0.68206597]\n",
      " [-0.77517105  0.41558018  0.57932412  0.8323167  -0.83034118]]\n",
      "\n",
      "Layer Normalization: \n",
      " [[-0.87558997 -1.07958857 -1.87064616  0.11541284  0.77748801]\n",
      " [-1.27882219  0.50998969  2.9568278   0.69247702 -1.02301053]\n",
      " [ 0.56452511  0.44375726  1.29738363 -0.09442868  0.73656758]\n",
      " [-0.70277616  0.87426804 -1.26721191 -0.30427021 -0.81840843]\n",
      " [-1.22121759  0.54310591  1.59910075  0.4826355  -0.94116969]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch Normalization: \\n\", batchnorm_forward(x, 1, 0)[0])\n",
    "print(\"\\nLayer Normalization: \\n\", layernorm_forward(x, 1, 0)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "723d4b7bc280cd31fdada53ad6420192b9a3a8d60631096143cc718cb9440dc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
